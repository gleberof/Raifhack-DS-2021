{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d362d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29328f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8981327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85322187",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a9de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "\n",
    "THRESHOLD = 0.15\n",
    "NEGATIVE_WEIGHT = 1.1\n",
    "\n",
    "def deviation_metric_one_sample(y_true: typing.Union[float, int], y_pred: typing.Union[float, int]) -> float:\n",
    "    \"\"\"\n",
    "    Реализация кастомной метрики для хакатона.\n",
    "\n",
    "    :param y_true: float, реальная цена\n",
    "    :param y_pred: float, предсказанная цена\n",
    "    :return: float, значение метрики\n",
    "    \"\"\"\n",
    "    deviation = (y_pred - y_true) / np.maximum(1e-8, y_true)\n",
    "    if np.abs(deviation) <= THRESHOLD:\n",
    "        return 0\n",
    "    elif deviation <= - 4 * THRESHOLD:\n",
    "        return 9 * NEGATIVE_WEIGHT\n",
    "    elif deviation < -THRESHOLD:\n",
    "        return NEGATIVE_WEIGHT * ((deviation / THRESHOLD) + 1) ** 2\n",
    "    elif deviation < 4 * THRESHOLD:\n",
    "        return ((deviation / THRESHOLD) - 1) ** 2\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "\n",
    "def deviation_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.array([deviation_metric_one_sample(y_true[n], y_pred[n]) for n in range(len(y_true))]).mean()\n",
    "\n",
    "def median_absolute_percentage_error(y_true: np.array, y_pred: np.array) -> float:\n",
    "    return np.median(np.abs(y_pred-y_true)/y_true)\n",
    "\n",
    "def metrics_stat(y_true: np.array, y_pred: np.array) -> typing.Dict[str,float]:\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mdape = median_absolute_percentage_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    raif_metric = deviation_metric(y_true, y_pred)\n",
    "    return {'mape':mape, 'mdape':mdape, 'rmse': rmse, 'r2': r2, 'raif_metric':raif_metric}\n",
    "\n",
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5415806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum  import IntEnum\n",
    "\n",
    "UNKNOWN_VALUE = 'missing'\n",
    "\n",
    "class PriceTypeEnum(IntEnum):\n",
    "\n",
    "    OFFER_PRICE = 0 # цена из объявления\n",
    "    MANUAL_PRICE = 1 # цена, полученная путем ручной оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ab2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_categorical(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Заполняет пропущенные категориальные переменные\n",
    "    :param df: dataframe, обучающая выборка\n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    fillna_cols = ['region','city','street','realty_type']\n",
    "    df_new[fillna_cols] = df_new[fillna_cols].fillna(UNKNOWN_VALUE)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d006eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_numerrical(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Заполняет пропущенные вещестенные переменные\n",
    "#     :param df: dataframe, обучающая выборка\n",
    "#     :return: dataframe\n",
    "#     \"\"\"\n",
    "#     df_new = df.copy()\n",
    "#     fillna_cols = ['region','city','street','realty_type']\n",
    "#     df_new[fillna_cols] = df_new[fillna_cols].fillna(UNKNOWN_VALUE)\n",
    "#     return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4491197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'per_square_meter_price'\n",
    "# признаки (или набор признаков), для которых применяем smoothed target encoding\n",
    "CATEGORICAL_STE_FEATURES = ['region', 'city', 'realty_type', 'month']\n",
    "\n",
    "# признаки, для которых применяем one hot encoding\n",
    "CATEGORICAL_OHE_FEATURES = []\n",
    "\n",
    "# численные признаки\n",
    "NUM_FEATURES = ['month_num', 'lat', 'lng', 'osm_amenity_points_in_0.001',\n",
    "       'osm_amenity_points_in_0.005', 'osm_amenity_points_in_0.0075',\n",
    "       'osm_amenity_points_in_0.01', 'osm_building_points_in_0.001',\n",
    "       'osm_building_points_in_0.005', 'osm_building_points_in_0.0075',\n",
    "       'osm_building_points_in_0.01', 'osm_catering_points_in_0.001',\n",
    "       'osm_catering_points_in_0.005', 'osm_catering_points_in_0.0075',\n",
    "       'osm_catering_points_in_0.01', 'osm_city_closest_dist',\n",
    "      'osm_city_nearest_population',\n",
    "       'osm_crossing_closest_dist', 'osm_crossing_points_in_0.001',\n",
    "       'osm_crossing_points_in_0.005', 'osm_crossing_points_in_0.0075',\n",
    "       'osm_crossing_points_in_0.01', 'osm_culture_points_in_0.001',\n",
    "       'osm_culture_points_in_0.005', 'osm_culture_points_in_0.0075',\n",
    "       'osm_culture_points_in_0.01', 'osm_finance_points_in_0.001',\n",
    "       'osm_finance_points_in_0.005', 'osm_finance_points_in_0.0075',\n",
    "       'osm_finance_points_in_0.01', 'osm_healthcare_points_in_0.005',\n",
    "       'osm_healthcare_points_in_0.0075', 'osm_healthcare_points_in_0.01',\n",
    "       'osm_historic_points_in_0.005', 'osm_historic_points_in_0.0075',\n",
    "       'osm_historic_points_in_0.01', 'osm_hotels_points_in_0.005',\n",
    "       'osm_hotels_points_in_0.0075', 'osm_hotels_points_in_0.01',\n",
    "       'osm_leisure_points_in_0.005', 'osm_leisure_points_in_0.0075',\n",
    "       'osm_leisure_points_in_0.01', 'osm_offices_points_in_0.001',\n",
    "       'osm_offices_points_in_0.005', 'osm_offices_points_in_0.0075',\n",
    "       'osm_offices_points_in_0.01', 'osm_shops_points_in_0.001',\n",
    "       'osm_shops_points_in_0.005', 'osm_shops_points_in_0.0075',\n",
    "       'osm_shops_points_in_0.01', 'osm_subway_closest_dist',\n",
    "       'osm_train_stop_closest_dist', 'osm_train_stop_points_in_0.005',\n",
    "       'osm_train_stop_points_in_0.0075', 'osm_train_stop_points_in_0.01',\n",
    "       'osm_transport_stop_closest_dist', 'osm_transport_stop_points_in_0.005',\n",
    "       'osm_transport_stop_points_in_0.0075',\n",
    "       'osm_transport_stop_points_in_0.01',\n",
    "       'reform_count_of_houses_1000', 'reform_count_of_houses_500',\n",
    "       'reform_house_population_1000', 'reform_house_population_500',\n",
    "       'reform_mean_floor_count_1000', 'reform_mean_floor_count_500',\n",
    "       'reform_mean_year_building_1000', 'reform_mean_year_building_500','total_square']\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.01,\n",
    "            reg_alpha=1,\n",
    "            num_leaves=40,\n",
    "            min_child_samples=5,\n",
    "            importance_type=\"gain\",\n",
    "            n_jobs=-1,\n",
    "            random_state=563,\n",
    "            objective='mape',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e49da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoeffBoostingModel():\n",
    "    \"\"\"\n",
    "    Модель представляет из себя sklearn pipeline. Пошаговый алгоритм:\n",
    "      1) в качестве обучения выбираются все данные с price_type=0\n",
    "      1) все фичи делятся на три типа (numerical_features, ohe_categorical_features, ste_categorical_features):\n",
    "          1.1) numerical_features - применяется StandardScaler\n",
    "          1.2) ohe_categorical_featires - кодируются через one hot encoding\n",
    "          1.3) ste_categorical_features - кодируются через SmoothedTargetEncoder\n",
    "      2) после этого все полученные фичи конкатенируются в одно пространство фичей и подаются на вход модели Lightgbm\n",
    "      3) делаем предикт на данных с price_type=1, считаем среднее отклонение реальных значений от предикта. Вычитаем это отклонение на финальном шаге (чтобы сместить отклонение к 0)\n",
    "\n",
    "    :param numerical_features: list, список численных признаков из датафрейма\n",
    "    :param ohe_categorical_features: list, список категориальных признаков для one hot encoding\n",
    "    :param ste_categorical_features, list, список категориальных признаков для smoothed target encoding.\n",
    "                                     Можно кодировать сразу несколько полей (например объединять категориальные признаки)\n",
    "    :\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numerical_features: typing.List[str],\n",
    "                 ohe_categorical_features: typing.List[str],\n",
    "                 ste_categorical_features: typing.List[typing.Union[str, typing.List[str]]],\n",
    "                 model_params: typing.Dict[str, typing.Union[str,int,float]]):\n",
    "        self.num_features = numerical_features\n",
    "        self.ohe_cat_features = ohe_categorical_features\n",
    "        self.ste_cat_features = ste_categorical_features\n",
    "\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', StandardScaler(), self.num_features),\n",
    "            ('ohe', OneHotEncoder(), self.ohe_cat_features),\n",
    "            ('ste', CatBoostEncoder(handle_missing='value', handle_unknown='value'), # OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), # CatBoostEncoder(handle_missing='value', handle_unknown='value'),\n",
    "             self.ste_cat_features)])\n",
    "\n",
    "        self.model = LGBMRegressor(**model_params)\n",
    "\n",
    "        self.pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('model', self.model)])\n",
    "\n",
    "        self._is_fitted = False\n",
    "        \n",
    "        self.coeff_model = LGBMRegressor(**model_params)\n",
    "        \n",
    "        self.coef_preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', StandardScaler(), self.num_features+['predictions']),\n",
    "            ('ohe', OneHotEncoder(), self.ohe_cat_features),\n",
    "            ('ste', CatBoostEncoder(handle_missing='value', handle_unknown='value'), # OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1), # CatBoostEncoder(handle_missing='value', handle_unknown='value'),\n",
    "             self.ste_cat_features)])\n",
    "        \n",
    "        self.coeff_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', self.coef_preprocessor),\n",
    "            ('model', self.coeff_model)])\n",
    "\n",
    "    def _find_corr_coefficient(self, X_manual: pd.DataFrame, y_manual: pd.Series):\n",
    "        \"\"\"Вычисление корректирующего коэффициента\n",
    "\n",
    "        :param X_manual: pd.DataFrame с ручными оценками\n",
    "        :param y_manual: pd.Series - цены ручника\n",
    "        \"\"\"\n",
    "        predictions = self.pipeline.predict(X_manual)\n",
    "        X_manual['predictions'] = self.pipeline.predict(X_manual)\n",
    "        self.coeff_pipeline.fit(X_manual, y_manual , model__feature_name=[f'{i}' for i in range(X_manual.shape[1])],\n",
    "                 model__sample_weight=1/y_manual.values)\n",
    "        self.__is_fitted = True\n",
    "\n",
    "    def fit(self, X_offer: pd.DataFrame, y_offer: pd.Series,\n",
    "            X_manual: pd.DataFrame, y_manual: pd.Series):\n",
    "        \"\"\"Обучение модели.\n",
    "        ML модель обучается на данных по предложениям на рынке (цены из объявления)\n",
    "        Затем вычисляется среднее отклонение между руяными оценками и предиктами для корректировки стоимости\n",
    "\n",
    "        :param X_offer: pd.DataFrame с объявлениями\n",
    "        :param y_offer: pd.Series - цена предложения (в объявлениях)\n",
    "        :param X_manual: pd.DataFrame с ручными оценками\n",
    "        :param y_manual: pd.Series - цены ручника\n",
    "        \"\"\"\n",
    "        print('Fit lightgbm')\n",
    "        self.pipeline.fit(X_offer, np.log1p(y_offer) , model__feature_name=[f'{i}' for i in range(X_offer.shape[1])],\n",
    "                         model__sample_weight=1/np.log1p(y_offer.values)) # ,model__categorical_feature=None)\n",
    "        print('Find corr coefficient')\n",
    "        self._find_corr_coefficient(X_manual, np.log1p(y_manual))\n",
    "        self.__is_fitted = True\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Предсказание модели Предсказываем преобразованный таргет, затем конвертируем в обычную цену через обратное\n",
    "        преобразование.\n",
    "\n",
    "        :param X: pd.DataFrame\n",
    "        :return: np.array, предсказания (цены на коммерческую недвижимость)\n",
    "        \"\"\"\n",
    "        if self.__is_fitted:\n",
    "            X['predictions'] = self.pipeline.predict(X)\n",
    "            predictions = np.expm1(np.clip(self.coeff_pipeline.predict(X), 5,15))\n",
    "            return predictions\n",
    "        else:\n",
    "            raise NotFittedError(\n",
    "                \"This {} instance is not fitted yet! Call 'fit' with appropriate arguments before predict\".format(\n",
    "                    type(self).__name__\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\"Сериализует модель в pickle.\n",
    "\n",
    "        :param path: str, путь до файла\n",
    "        \"\"\"\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(self, path: str):\n",
    "        \"\"\"Сериализует модель в pickle.\n",
    "\n",
    "        :param path: str, путь до файла\n",
    "        :return: Модель\n",
    "        \"\"\"\n",
    "        with open(path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973117df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0610429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train:pd.DataFrame, \n",
    "                    split_coulmn:str = 'price_type',\n",
    "                    val_to_check:int = 0,\n",
    "                    columns: List[str] = NUM_FEATURES,\n",
    "                    strategy:str = 'drop',\n",
    "                    sigma_tolerance:float = 3.0,\n",
    "                   ) -> pd.DataFrame:\n",
    "    \n",
    "    train_to_check_orig = train[train[split_coulmn] == val_to_check]\n",
    "    train_to_check = train_to_check_orig.copy()\n",
    "    train_sample = train[train[split_coulmn] != val_to_check]\n",
    "    \n",
    "    stats = {}\n",
    "    for col in tqdm(columns):\n",
    "        mean = train_sample[col].mean()\n",
    "        sigma = train_sample[col].std()\n",
    "        min_val, max_val = mean - sigma_tolerance * sigma, mean + sigma_tolerance * sigma\n",
    "        stats[col] = (min_val, max_val)\n",
    "        train_to_check = train_to_check[(train_to_check[col] > min_val) & (train_to_check[col] < max_val)]\n",
    "        \n",
    "        \n",
    "    train_result = pd.concat((train_to_check, train_sample)).reset_index(drop=True)\n",
    "    \n",
    "#     if strategy == 'impute':\n",
    "#         train_missing = train_to_check_orig[~train_to_check_orig.id.isin(train_result.id.values)].reset_index(drop=True)\n",
    "#         index_vecs = np.vstack(train_result[['lat', 'lng']].astype(np.float32).values)\n",
    "#         index_find = np.vstack(train_missing[['lat', 'lng']].astype(np.float32).values)\n",
    "#         index = faiss.IndexFlatL2(2)\n",
    "#         index.add(index_vecs)\n",
    "#         print(\"Creating index about 1 min\")\n",
    "#         D, I = index.search(index_find, 1) \n",
    "#         extract_df = train_result.loc[I.flatten()].reset_index(drop=True)\n",
    "#         for col in tqdm(columns):\n",
    "#             (min_val, max_val) = stats[col]\n",
    "#             ind = train_missing[(train_missing[col] <= min_val) | (train_missing[col] >= max_val)].index\n",
    "#             train_missing.loc[ind, col] = extract_df.loc[ind, col]\n",
    "            \n",
    "#         train_result = pd.concat((train_result, train_missing)).reset_index(drop=True)\n",
    "    \n",
    "    return train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597e41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32b52677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('../data/train.csv')\n",
    "test_path = Path('../data/test.csv')\n",
    "submission_path = Path('../data/test_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19bd80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6c929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egleb/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "train_df['month'] = pd.to_datetime(train_df['date']).dt.month\n",
    "train_df['month_num'] = pd.to_datetime(train_df['date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4062e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279792, 79)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18838de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8222d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_new = preprocess_data(train_df, strategy = 'drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d049512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_new = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac83536b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279792, 79)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f80da1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (best_split_info.right_count) > (0) at /__w/1/s/python-package/compile/src/treelearner/serial_tree_learner.cpp, line 663 .\n",
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (best_split_info.right_count) > (0) at /__w/1/s/python-package/compile/src/treelearner/serial_tree_learner.cpp, line 663 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2122635/2637659521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                           ste_categorical_features=CATEGORICAL_STE_FEATURES, model_params=MODEL_PARAMS)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_offer_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offer_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_manual_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_manual_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpredictions_manual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_manual_vl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2122635/1980198753.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_offer, y_offer, X_manual, y_manual)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit lightgbm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         self.pipeline.fit(X_offer, np.log1p(y_offer) , model__feature_name=[f'{i}' for i in range(X_offer.shape[1])],\n\u001b[0m\u001b[1;32m     78\u001b[0m                          model__sample_weight=1/np.log1p(y_offer.values)) # ,model__categorical_feature=None)\n\u001b[1;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Find corr coefficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[1;32m    817\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[1;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/raif-hack-dLUNAmKH-py3.8/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (best_split_info.right_count) > (0) at /__w/1/s/python-package/compile/src/treelearner/serial_tree_learner.cpp, line 663 .\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=239)\n",
    "metrics_arr = []\n",
    "predicts_arr = []\n",
    "for fold, (tr,va) in enumerate(kf.split(train_df_new, train_df_new['price_type'])):\n",
    "    df_tr = prepare_categorical(train_df_new.loc[tr].reset_index(drop=True))\n",
    "    df_vl = prepare_categorical(train_df_new.loc[va].reset_index(drop=True))\n",
    "    \n",
    "    X_offer_tr = df_tr[df_tr.price_type == PriceTypeEnum.OFFER_PRICE][NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    y_offer_tr = df_tr[df_tr.price_type == PriceTypeEnum.OFFER_PRICE][TARGET]\n",
    "    \n",
    "    X_offer_vl = df_vl[df_vl.price_type == PriceTypeEnum.OFFER_PRICE][NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    y_offer_vl = df_vl[df_vl.price_type == PriceTypeEnum.OFFER_PRICE][TARGET]\n",
    "    \n",
    "    \n",
    "    X_manual_tr = df_tr[df_tr.price_type == PriceTypeEnum.MANUAL_PRICE][NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    y_manual_tr = df_tr[df_tr.price_type == PriceTypeEnum.MANUAL_PRICE][TARGET]\n",
    "    \n",
    "    X_manual_vl = df_vl[df_vl.price_type == PriceTypeEnum.MANUAL_PRICE][NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]\n",
    "    y_manual_vl = df_vl[df_vl.price_type == PriceTypeEnum.MANUAL_PRICE][TARGET]\n",
    "    X_manual_vl_id = df_vl[df_vl.price_type == PriceTypeEnum.MANUAL_PRICE]['id']\n",
    "    \n",
    "    \n",
    "    model = CoeffBoostingModel(numerical_features=NUM_FEATURES, ohe_categorical_features=CATEGORICAL_OHE_FEATURES,\n",
    "                          ste_categorical_features=CATEGORICAL_STE_FEATURES, model_params=MODEL_PARAMS)\n",
    "    \n",
    "    model.fit(X_offer_tr, y_offer_tr, X_manual_tr, y_manual_tr)\n",
    "    \n",
    "    predictions_manual = model.predict(X_manual_vl)\n",
    "    metrics = metrics_stat(y_manual_vl.values, predictions_manual)\n",
    "    predicts_arr.append(pd.DataFrame((X_manual_vl_id, predictions_manual), columns=['id', f'predict_{fold}']))\n",
    "    print(f'fold: {fold}, metrics {metrics}')\n",
    "    metrics_arr.append(metrics)\n",
    "    model.save(f\"model_bst_1_{fold}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([e['raif_metric'] for e in metrics_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63173e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "#1.9456598148702269\n",
    "#1.950442347124326\n",
    "#1.9597450099363427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e459b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LB\n",
    "#1.8021098072169865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73bac09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path)\n",
    "test_df['month'] = pd.to_datetime(test_df['date']).dt.month\n",
    "test_df['month_num'] = pd.to_datetime(test_df['date']).dt.month\n",
    "pred_df = prepare_categorical(test_df)[NUM_FEATURES+CATEGORICAL_OHE_FEATURES+CATEGORICAL_STE_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd7ef81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 0\n",
    "\n",
    "for ifold in range(FOLDS):\n",
    "    model = CoeffBoostingModel(numerical_features=NUM_FEATURES, ohe_categorical_features=CATEGORICAL_OHE_FEATURES,\n",
    "                          ste_categorical_features=CATEGORICAL_STE_FEATURES, model_params=MODEL_PARAMS)\n",
    "    model = model.load(f\"model_bst_{fold}.bin\")\n",
    "    y_score = model.predict(pred_df)\n",
    "    pred += y_score / FOLDS\n",
    "test_sub = pd.read_csv(test_path)[['id']]\n",
    "test_sub[TARGET] = pred\n",
    "test_sub.to_csv('boots_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfde0530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350709.5313423764"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub['per_square_meter_price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad36df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22168.363246630317"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub['per_square_meter_price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f085db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
